{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file\n",
    "df = pd.read_csv('tanglaw_data.csv')\n",
    "\n",
    "#make a small dataset\n",
    "df_small = df.sample(n = 58, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get columns based on column names\n",
    "X = df_small[['B1','B2','B3',\n",
    "      'B4','B5','B6','B7']] #if more than 1 column, list of columns must be specified\n",
    "y = df_small['Chl-a'] #provide the column name if only 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, we have to deal with small datasets and creating big validation sets  means losing a lot of data for the model to learn. In those cases, we can opt for a  type of k-fold cross-validation where k=N, where N is the number of samples in the  dataset (No need to create train and test set). This means that in all folds of training, we will be training on all data  samples except 1. The number of folds for this type of cross-validation is the same  as the number of samples that we have in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.24695953e-01 -1.67979396e+00 -4.61148023e+00 -1.04679437e+00\n",
      " -7.05431388e+00 -2.27891424e+00 -3.12121511e+00 -1.46812273e+00\n",
      " -4.41815428e-01 -5.77246658e+00 -2.39023935e+00 -5.83482874e-01\n",
      " -2.11902880e+00 -6.22452596e+00 -5.15129205e+00 -1.07580005e+00\n",
      " -1.07597542e+00 -7.21709369e-01 -3.23549242e+00 -1.71771749e+00\n",
      " -2.21597321e+01 -6.50625822e+00 -1.71181072e+00 -6.51862077e-01\n",
      " -3.10194710e+00 -4.07650523e+00 -2.35297980e+00 -6.03855616e-01\n",
      " -1.40059670e+00 -2.59711450e+00 -1.55919017e+00 -3.73484254e-01\n",
      " -1.38699506e+00 -1.69176533e+00 -1.87197417e+00 -2.99615201e-01\n",
      " -4.80121731e+00 -1.53704119e+00 -1.19591824e+00 -4.81590354e-01\n",
      " -8.05303420e-01 -4.33042218e+00 -6.70803700e-01 -3.48182975e-03\n",
      " -6.38111806e+00 -3.15913986e+00 -2.59061939e+00 -3.42985069e+00\n",
      " -2.28208688e-01 -4.23408414e+00 -8.84648925e-01 -1.18476755e+00\n",
      " -3.33508711e-02 -4.27459420e+00 -1.95748442e+00 -4.91841818e+00\n",
      " -8.52768495e-01 -2.08200686e+00]\n",
      "average: -2.6616793278320046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model = LinearRegression()\n",
    "scores = cross_val_score(model, \n",
    "                         X, y, cv = len(X), # the number of rows in a dataframe\n",
    "                        scoring = 'neg_root_mean_squared_error' # ignore the negative sign\n",
    "                        )\n",
    "print(scores)\n",
    "print(f'average: {scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
